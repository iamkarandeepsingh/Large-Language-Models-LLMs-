{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30f4f2e-87d0-4560-a212-2a2621fe7bc3",
   "metadata": {},
   "source": [
    "### HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60204a9e-fe9e-43a5-ae7a-5ea0e4ea7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\karan\\anaconda3\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in c:\\users\\karan\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\karan\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karan\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\karan\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\karan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdab31b-5c57-46ec-9928-7d7f2785ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34acc0b6-bf81-41bb-b555-eb06aa6be2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2975a18-4a7b-41ee-b8bf-9ebed49c12fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee70d7d2-3559-49df-b143-0f8ece0282d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999734103679657}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\"I am excited to learn about large language models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0fdcd91-0ec7-47c6-8ee7-994541a2a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model = \"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db9989c-afe9-4475-a986-cc35911d56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99863416,\n",
       "  'index': 4,\n",
       "  'word': 'John',\n",
       "  'start': 12,\n",
       "  'end': 16},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9995042,\n",
       "  'index': 9,\n",
       "  'word': 'Montreal',\n",
       "  'start': 33,\n",
       "  'end': 41},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.9975923,\n",
       "  'index': 11,\n",
       "  'word': 'Morgan',\n",
       "  'start': 46,\n",
       "  'end': 52},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9981583,\n",
       "  'index': 12,\n",
       "  'word': 'Stanley',\n",
       "  'start': 53,\n",
       "  'end': 60}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"His name is John and he works in Montreal for Morgan Stanley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35837f18-a353-4009-875d-6e6e8d484268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model = \"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd25bbc6-a0f9-403a-9c9f-1e6fd6a587cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeunce_to_classify = \"I will graduate from Concordia University this summer.\"\n",
    "candidate_labels = ['travel', 'academic', 'cooking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fabdbf9-6977-4766-a79a-2e5068add919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I will graduate from Concordia University this summer.',\n",
       " 'labels': ['academic', 'travel', 'cooking'],\n",
       " 'scores': [0.970462441444397, 0.025085192173719406, 0.00445235799998045]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classifier(seqeunce_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e4a11-19dd-4cb3-a899-e1e4bf1567d0",
   "metadata": {},
   "source": [
    "### Pre Trained Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b45891ee-c1e1-4214-bd0a-81a716bc06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a2fd53-7fde-4dbf-bd23-57451d4e0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1058bc44-fe32-4d90-b6da-ddbf69130bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44ed0c0f-0df1-472e-a7e3-d1a5cc753b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am excited to graduate from Concordia University this summer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f7d50b8-fbd1-42cc-91ad-3ff7c7b325b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2572, 7568, 2000, 4619, 2013, 24982, 2118, 2023, 2621, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(sentence)\n",
    "print (input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98aca515-ac45-456f-93cb-0edee50a9c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'excited', 'to', 'graduate', 'from', 'concordia', 'university', 'this', 'summer', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d96ba17-52e4-411f-a055-54cb3a7b648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 2572, 7568, 2000, 4619, 2013, 24982, 2118, 2023, 2621, 1012]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print (token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9a4bc88-01eb-47b1-b940-ef198c363d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am excited to graduate from concordia university this summer.\n"
     ]
    }
   ],
   "source": [
    "decoded_ids = tokenizer.decode(token_ids)\n",
    "print (decoded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9b32d1b-c57b-414c-aab8-e6df8da42e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [SEP]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101,102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ef9c163-5557-41f5-b90c-2ef8ae4ea460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f17ec6ca-8a55-4d1e-bdb4-41837357d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer2 = AutoTokenizer.from_pretrained(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bf91ecf-48dc-4858-a8ee-3dc1a77e2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"I am excited to graduate from Concordia University this summer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a52a36c3-a057-459f-9175-0fea5c4701be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [35, 569, 5564, 22, 3868, 40, 16479, 780, 315, 52, 1148, 9, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer2(sentence2)\n",
    "print (input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "338d7376-3334-487c-bbbe-b3b769cc1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁am', '▁excited', '▁to', '▁graduate', '▁from', '▁Concord', 'ia', '▁University', '▁this', '▁summer', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens2 = tokenizer2.tokenize(sentence)\n",
    "print (tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5371b40-6341-4833-bb22-76ba820bc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 569, 5564, 22, 3868, 40, 16479, 780, 315, 52, 1148, 9]\n"
     ]
    }
   ],
   "source": [
    "token_ids2 = tokenizer2.convert_tokens_to_ids(tokens2)\n",
    "print (token_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "159b8604-76e1-4819-b5bd-01eba0ee4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am excited to graduate from Concordia University this summer.\n"
     ]
    }
   ],
   "source": [
    "decoded_ids2 = tokenizer2.decode(token_ids2)\n",
    "print (decoded_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dc507da-41b7-4617-bbe7-4a18b271283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sep><cls>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2.decode([4,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04685d-bee8-4078-b53a-3d1be6938417",
   "metadata": {},
   "source": [
    "### HuggingFace and PyTorch/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a230ec-4ab3-40aa-86ec-5b0ce681c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9731b9d-3a34-4dd7-b342-6c5cdcd406f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am excited to graduate from Concordia University this summer.\n",
      "{'input_ids': [35, 569, 5564, 22, 3868, 40, 16479, 780, 315, 52, 1148, 9, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print (sentence)\n",
    "print (input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b87b50d3-e959-466f-96d1-c1a0d3ec1299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7715ad2f9e74822b9fca5bc94e15b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\karan\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe635e666f04d2f91a4d8b5649ffabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cfaaa2b1854e699a74f54c7e7eb2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f8a31dd-cb72-4cee-b5db-6b83965f70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  2572,  7568,  2000,  4619,  2013, 24982,  2118,  2023,\n",
      "          2621,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "input_ids_pt = tokenizer(sentence, return_tensors = \"pt\")\n",
    "print (input_ids_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "115b2b21-ca52-4843-8112-302f553fcdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713aaa92e8354975a5632444885e22a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "646725b9-0976-45e7-a78a-1cf5488d36f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**input_ids_pt).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd703f-59fc-485f-8a7d-d3d9a7dffaba",
   "metadata": {},
   "source": [
    "### Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b7b8de7-0b23-4fe0-9e96-296a712be49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63c40dca-5d69-4113-a826-2a144cd6e161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_models\\\\tokenizer_config.json',\n",
       " 'saved_models\\\\special_tokens_map.json',\n",
       " 'saved_models\\\\vocab.txt',\n",
       " 'saved_models\\\\added_tokens.json',\n",
       " 'saved_models\\\\tokenizer.json')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0694790-3571-4915-b694-578cf7fd71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ac3aff5-06be-46b6-ae5f-ed92c625d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer = AutoTokenizer.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "131640c2-3d28-4a87-bf15-e373f3343549",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = AutoModelForSequenceClassification.from_pretrained(model_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
